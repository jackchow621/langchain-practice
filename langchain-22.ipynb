{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0d973d-d74b-4eb7-ae6c-acb2b5d32d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置OpenAI API密钥\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = 'Your OpenAI Key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed43cdb-8943-488d-b82f-bc09f743e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库和模块\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 创建一个聊天模型的实例\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "# 创建一个消息列表\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是一个花卉行家。\"),\n",
    "    HumanMessage(content=\"朋友喜欢淡雅的颜色，她的婚礼我选择什么花？\")\n",
    "]\n",
    "\n",
    "# 使用聊天模型获取响应\n",
    "response = chat(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222157e-add2-462c-b02f-9656166ef4fa",
   "metadata": {},
   "source": [
    "# 命令行聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b0c16-0283-4256-9483-4c4a847eb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库和模块\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 定义一个命令行聊天机器人的类\n",
    "class CommandlineChatbot:\n",
    "    # 在初始化时，设置花卉行家的角色并初始化聊天模型\n",
    "    def __init__(self):\n",
    "        self.chat = ChatOpenAI()\n",
    "        self.messages = [SystemMessage(content=\"你是一个花卉行家。\")]\n",
    "\n",
    "    # 定义一个循环来持续与用户交互\n",
    "    def chat_loop(self):\n",
    "        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n",
    "        while True:\n",
    "            user_input = input(\"你: \")\n",
    "            # 如果用户输入“exit”，则退出循环\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"再见!\")\n",
    "                break\n",
    "            # 将用户的输入添加到消息列表中，并获取机器人的响应\n",
    "            self.messages.append(HumanMessage(content=user_input))\n",
    "            response = self.chat(self.messages)\n",
    "            print(f\"Chatbot: {response.content}\")\n",
    "\n",
    "# 如果直接运行这个脚本，启动聊天机器人\n",
    "if __name__ == \"__main__\":\n",
    "    bot = CommandlineChatbot()\n",
    "    bot.chat_loop()# 设置OpenAI API密钥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8565b-8625-404c-aedd-15345ed7f8cc",
   "metadata": {},
   "source": [
    "# 带记忆的聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef6309-1959-4b8d-852a-7efe137ddf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库和模块\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# 带记忆的聊天机器人类\n",
    "class ChatbotWithMemory:\n",
    "    def __init__(self):\n",
    "\n",
    "        # 初始化LLM\n",
    "        self.llm = ChatOpenAI()\n",
    "\n",
    "        # 初始化Prompt\n",
    "        self.prompt = ChatPromptTemplate(\n",
    "            messages=[\n",
    "                SystemMessagePromptTemplate.from_template(\n",
    "                    \"你是一个花卉行家。你通常的回答不超过30字。\"\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 初始化Memory\n",
    "        self.memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "        \n",
    "        # 初始化LLMChain with LLM, prompt and memory\n",
    "        self.conversation = LLMChain(\n",
    "            llm=self.llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=True,\n",
    "            memory=self.memory\n",
    "        )\n",
    "\n",
    "    # 与机器人交互的函数\n",
    "    def chat_loop(self):\n",
    "        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n",
    "        while True:\n",
    "            user_input = input(\"你: \")\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"再见!\")\n",
    "                break\n",
    "            \n",
    "            response = self.conversation({\"question\": user_input})\n",
    "            print(f\"Chatbot: {response['text']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 启动Chatbot\n",
    "    bot = ChatbotWithMemory()\n",
    "    bot.chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9f631-b21a-4fb2-84e2-b696dc68d669",
   "metadata": {},
   "source": [
    "# 带检索功能的聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a31c89-9e02-4a9f-b3a2-7ee31ceeb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import TextLoader \n",
    "\n",
    "# ChatBot类的实现-带检索功能\n",
    "class ChatbotWithRetrieval:\n",
    "\n",
    "    def __init__(self, dir):\n",
    "\n",
    "        # 加载Documents\n",
    "        base_dir = dir # 文档的存放目录\n",
    "        documents = []\n",
    "        for file in os.listdir(base_dir): \n",
    "            file_path = os.path.join(base_dir, file)\n",
    "            if file.endswith('.pdf'):\n",
    "                loader = PyPDFLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "            elif file.endswith('.docx') or file.endswith('.doc'):\n",
    "                loader = Docx2txtLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "            elif file.endswith('.txt'):\n",
    "                loader = TextLoader(file_path)\n",
    "                documents.extend(loader.load())\n",
    "        \n",
    "        # 文本的分割\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "        all_splits = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # 向量数据库\n",
    "        self.vectorstore = Qdrant.from_documents(\n",
    "            documents=all_splits, # 以分块的文档\n",
    "            embedding=OpenAIEmbeddings(), # 用OpenAI的Embedding Model做嵌入\n",
    "            location=\":memory:\",  # in-memory 存储\n",
    "            collection_name=\"my_documents\",) # 指定collection_name\n",
    "        \n",
    "        # 初始化LLM\n",
    "        self.llm = ChatOpenAI()\n",
    "        \n",
    "        # 初始化Memory\n",
    "        self.memory = ConversationSummaryMemory(\n",
    "            llm=self.llm, \n",
    "            memory_key=\"chat_history\", \n",
    "            return_messages=True\n",
    "            )\n",
    "        \n",
    "        # 设置Retrieval Chain\n",
    "        retriever = self.vectorstore.as_retriever()\n",
    "        self.qa = ConversationalRetrievalChain.from_llm(\n",
    "            self.llm, \n",
    "            retriever=retriever, \n",
    "            memory=self.memory\n",
    "            )\n",
    "\n",
    "    # 交互对话的函数\n",
    "    def chat_loop(self):\n",
    "        print(\"Chatbot 已启动! 输入'exit'来退出程序。\")\n",
    "        while True:\n",
    "            user_input = input(\"你: \")\n",
    "            if user_input.lower() == 'exit':\n",
    "                print(\"再见!\")\n",
    "                break\n",
    "            # 调用 Retrieval Chain  \n",
    "            response = self.qa(user_input)\n",
    "            print(f\"Chatbot: {response['answer']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 启动Chatbot\n",
    "    folder = \"OneFlower\"\n",
    "    bot = ChatbotWithRetrieval(folder)\n",
    "    bot.chat_loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
